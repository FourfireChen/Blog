# 操作系统学习简记二——内存基础

## 内存层次结构

从上到下

*   寄存器
*   Ln缓存
*   主存（物理内存）
*   硬盘（包括虚拟内存）

## 内存管理的目标

*   抽象：简单的逻辑地址空间，相当于一个大数组
*   保护：隔离不同进程
*   共享：安全可靠有效的进程间数据交互
*   虚拟化：虚拟化出更多的内存空间

## 地址空间

### 定义

*   物理地址空间：硬件
*   逻辑地址空间：应用程序拥有的内存范围
*   MMU：**用于分页机制**，位于CPU中，缓存了逻辑地址和物理地址的映射关系。完整的映射关系储存在内存中，MMU是为了加快CPU对逻辑地址和物理地址转换时的速度。

### 逻辑地址生成

*   编译：-&gt;.s文件，汇编语言
*   汇编：-&gt;.o文件，机器指令。把宏定义以及变量名等等转成一个段内的地址
*   链接：-&gt;.exe，将互相依赖的.o文件合成（比如调用某些库）。原本的地址需要再次转换成同一个段内的。
*   载入：将.exe文件加载进内存中，需要进行程序重定位。将.exe中的地址再次转换，成逻辑地址。

### 物理地址生成

*   取逻辑地址（指令中指定）
*   根据逻辑地址在MMU中查找对应的物理地址，如果查不到，去内存中查找。
*   根据物理地址跟主存请求对应内容，主存从总线把内容返还CPU。

## 连续内存分配

### 内存碎片

*   外部碎片：没有分配给应用程序又无法使用的碎片地址空间
*   内部碎片：已经分配给应用程序但无法使用的碎片地址空间

### 动态分配

* 第一匹配分配（首次分配）：使用第一个能满足要求的内存空闲块

      *   对空闲块按地址排序
      
      *   容易产生外部碎片

* 最优匹配分配：找到最适合的，也即使用和需求大小差距最小的空闲块

      *   对空闲块按大小排序
      
      *   可能出现很多微小外部碎片

* 最差匹配分配：使用和需求大小差距最大的空闲块

      *   对空闲块按大小排序
  *   容易破碎大的空闲块，导致大分区难以被分配

### 碎片整理

*   压缩式：压缩、紧凑已使用的地址空间，把碎片空间往一个方向集中
*   交换式：使用swap硬盘空间

### 伙伴系统

*   可分配的分区大小只能是2的某次方
*   需要的分区大小为2的某-1次方到2的某次方时，把整块分配给该进程

这种处理方法可以减少碎片的空间

#### 实现（Buddy system）

##### 分配

*   由小到大找到最小的可用空间块；
*   如果空闲块过大，二分，直到大于其二分之一。

##### 释放

* 把释放块放入空闲块数组；
* 合并：

      *   大小相同
  *   地址相邻
  *   低地址的块的起始地址必须是2的整数倍

## 非连续内存分配

### 为什么要有非连续内存分配

* 连续内存存在比较大的缺点

  + 利用率低

  *   碎片多

* 支持共享地址空间
* 支持动态加载

### 分段

现代操作系统使用比较少，80X86用的是这个

#### 想法

根据应用程序使用的不同作用的地址段，把地址段分散到多个物理地址空间。如堆、栈、程序数据等等。

#### 实现

* 使用段访问机制，用段地址和偏移地址进行寻址，具体实现有两种：

  + 使用段寄存器和偏移寄存器；

  *   使用单地址，上部分是段地址，下部分是偏移地址

* 具体实现方案：

  1. 根据段号去段表（由操作系统初始化设置）中查到该段的首地址和长度

  2.  判断偏移地址是否在合理区间内（和长度对比）
  3.  偏移地址和段的首地址加起来得到物理地址

### 分页

现代操作系统使用比较多

#### 想法

划分物理内存至固定大小的**帧**（frame），划分逻辑地址空间到至和物理页帧相同大小的**页**（page）。

这里注意称呼，**物理内存上称为帧，逻辑空间上称为页**。

整体上和分段的想法类似，划分物理内存，但页帧大小固定。

#### 物理地址（页帧）的计算

以单地址表示为例，前F位为帧号（f），后S位为偏移地址（o）。因此2^S表示的是一个帧的大小，因而有：

`物理地址=2^S*f+o`

#### 逻辑地址（页）的计算

计算公式与页帧相同，而且偏移地址和其真实对应的物理地址的偏移地址相同。

不同的地方在于表示页号的位数和表示帧号的位数可以不同（帧大小和页大小相同），因为虚拟地址可以虚拟出比实际物理地址要大得多的空间。

#### 页寻址机制

1.  根据**页号**在页表（由操作系统建立）中查到**页帧号**
2.  结合偏移地址（同一个），可计算出逻辑地址和物理地址。

#### 页表

**每个应用程序对应一个页表，建立专属的逻辑地址到物理地址的映射关系集。**

页表是一个大数组，其索引号是页号，对应的元素是某些标记位（可标记状态，如该页帧是否正在使用、页帧是否存在）和帧号的组合。

#### 问题

* 访问一次内存单元要做2次内存访问

  + 一次访问页表，获取帧号

  *   一次访问数据

* 页表可能非常大
* 每个应用程序都有自己的页表

#### 优化

*   缓存
*   多级间接访问

##### 缓存

TLB，位于MMU中，也就是在CPU中，全称Translation Look-aside Buffer，缓存近期访问的页帧转换表项。

每次访问内存时，先使用TLB，如果命中，访问速度很快；如果没有命中，只能去查页表，但就把查到的表项更新到TLB中。

**TLB的命中率不会很低，因为在现代操作系统中，页大小一般是4K，这样就意味着4K的空间使用的是同一个页号/帧号，也即每4K个数据需要查一个新的页号，可以接受。同时，在程序设计时，尽量使程序具有局部性，增加TLB命中率。**

##### 分级间接访问——分级

* 二级页表

    页号分为两个，p1和p2，以p1为索引（index）在一级页表中找到元素，该值为二级页表的起始地址，再加p2得到帧号。

* 多级页表类似

* 需要多次访问导致有时间上的损耗

* 空间上有很大的节省，上级页表记录的只是下级页表的首地址，如果映射关系存在，理论上来说还比不分级需要的空间更大，但有很多的映射关系是不存在的，就不需要下级页表，直接节省大段的空间。

##### 分级间接访问——反向页表

分级页表仍然存在大地址问题，其占用空间直接由逻辑地址大小决定，反向页表要解决的是以物理地址大小决定页映射关系的存储。

目前cpu比较少使用反向页表

* 主要思想：以页帧来索引页
* 基于页寄存器的方案

      *   使用一个页寄存器，与页表相反，即用帧号为索引，页号为元素
  *   要实现的是以页号查帧号，非常麻烦

* 基于关联内存的方案
* 基于hash查找的方案：以哈系计算，将页号映射到帧号。

### 段页式

结合段式和页式

*   在段式存储的基础上，给每个段加一级页表；

#### 实现

每个进程对应一个段表，段表中的各种段，对应一个页表，页表再对应物理地址。

进程内存共享

基于段页式可以简便实现内存共享，可以开辟一个共享段，不同进程的共享段指向同一个页表。
